## Fast Nginx Task Startup with ECS Managed Instances
## ä½¿ç”¨ ECS Managed Instances å¿«é€Ÿå•Ÿå‹• Nginx ä»»å‹™

This project demonstrates how to use **Amazon ECS Managed Instances** with Terraform to quickly bring up an ECS service running Nginx.
æœ¬å°ˆæ¡ˆå±•ç¤ºå¦‚ä½•ä½¿ç”¨ Terraform æ­é… **Amazon ECS Managed Instances** å¿«é€Ÿå•Ÿå‹•é‹è¡Œ Nginx çš„ ECS æœå‹™ã€‚

We also measure how long it takes from requesting a single task to the moment the application starts logging â€” roughly **40 seconds end-to-end**.
æˆ‘å€‘ä¹Ÿæ¸¬é‡äº†å¾è«‹æ±‚å–®ä¸€ä»»å‹™åˆ°æ‡‰ç”¨ç¨‹å¼é–‹å§‹è¨˜éŒ„æ—¥èªŒæ‰€éœ€çš„æ™‚é–“ â€” ç«¯åˆ°ç«¯å¤§ç´„ **40 ç§’**ã€‚

- **Why ECS Managed Instances are interesting and useful**
- **ç‚ºä»€éº¼ ECS Managed Instances å€¼å¾—é—œæ³¨ä¸”å¯¦ç”¨**

- **What this Terraform example is doing at a high level**
- **é€™å€‹ Terraform ç¯„ä¾‹åœ¨é«˜å±¤æ¬¡ä¸Šåšäº†ä»€éº¼**

- **Measured time from "no instances" to "first task running Nginx"**
- **æ¸¬é‡å¾ã€Œç„¡å¯¦ä¾‹ã€åˆ°ã€Œç¬¬ä¸€å€‹ Nginx ä»»å‹™é‹è¡Œã€çš„æ™‚é–“**

---

## Why Care About ECS Managed Instances?
## ç‚ºä»€éº¼è¦é—œå¿ƒ ECS Managed Instancesï¼Ÿ

When running workloads (tasks / services) on ECS, we typically think in terms of two classic options:
ç•¶åœ¨ ECS ä¸Šé‹è¡Œå·¥ä½œè² è¼‰ï¼ˆä»»å‹™/æœå‹™ï¼‰æ™‚ï¼Œæˆ‘å€‘é€šå¸¸æœƒæƒ³åˆ°å…©ç¨®ç¶“å…¸é¸é …ï¼š

- **ECS on EC2**: You manage Auto Scaling Groups, lifecycle, capacity, patching, etc.
- **ECS on EC2**ï¼šæ‚¨éœ€è¦è‡ªè¡Œç®¡ç† Auto Scaling Groupsã€ç”Ÿå‘½é€±æœŸã€å®¹é‡ã€ä¿®è£œç¨‹å¼ç­‰ã€‚

- **ECS on Fargate**: No EC2 management, but higher per-unit cost and some limitations on supported sizes.
- **ECS on Fargate**ï¼šç„¡éœ€ç®¡ç† EC2ï¼Œä½†å–®ä½æˆæœ¬è¼ƒé«˜ä¸”æ”¯æ´çš„è¦æ ¼æœ‰ä¸€äº›é™åˆ¶ã€‚

**ECS Managed Instances** sit somewhere in between:
**ECS Managed Instances** ä»‹æ–¼å…©è€…ä¹‹é–“ï¼š

- You still use EC2 instances (so you can leverage Graviton, Spot, flexible instance families, etc.).
- æ‚¨ä»ç„¶ä½¿ç”¨ EC2 å¯¦ä¾‹ï¼ˆå› æ­¤å¯ä»¥åˆ©ç”¨ Gravitonã€Spotã€å½ˆæ€§å¯¦ä¾‹ç³»åˆ—ç­‰ï¼‰ã€‚

- But you **don't manage ASGs yourself**. ECS uses a capacity provider to manage the EC2 instances for you â€” essentially "auto-managed EC2 capacity powered by ECS".
- ä½†æ‚¨**ä¸éœ€è¦è‡ªå·±ç®¡ç† ASG**ã€‚ECS ä½¿ç”¨å®¹é‡æä¾›è€…ç‚ºæ‚¨ç®¡ç† EC2 å¯¦ä¾‹ â€” æœ¬è³ªä¸Šæ˜¯ã€Œç”± ECS é©…å‹•çš„è‡ªå‹•ç®¡ç† EC2 å®¹é‡ã€ã€‚

For SREs/platform teams, this means:
å°æ–¼ SRE/å¹³å°åœ˜éšŠä¾†èªªï¼Œé€™æ„å‘³è‘—ï¼š

- You define a **pool of instances by attributes (instance requirements)**, e.g. ARM architecture, 2 vCPUs, 4â€“6 GB memory, etc.
- æ‚¨å¯ä»¥é€é**å±¬æ€§ï¼ˆå¯¦ä¾‹éœ€æ±‚ï¼‰å®šç¾©ä¸€çµ„å¯¦ä¾‹æ± **ï¼Œä¾‹å¦‚ ARM æ¶æ§‹ã€2 å€‹ vCPUã€4-6 GB è¨˜æ†¶é«”ç­‰ã€‚

- You don't maintain ASGs and scaling policies directly; instead, you use an **ECS capacity provider strategy** to select capacity sources.
- æ‚¨ä¸éœ€è¦ç›´æ¥ç¶­è­· ASG å’Œæ“´å±•ç­–ç•¥ï¼›ç›¸åï¼Œæ‚¨ä½¿ç”¨ **ECS å®¹é‡æä¾›è€…ç­–ç•¥**ä¾†é¸æ“‡å®¹é‡ä¾†æºã€‚

- With CloudWatch Logs and Container Insights, the operational experience is close to Fargate, but the cost and flexibility look much more like EC2.
- é€é CloudWatch Logs å’Œ Container Insightsï¼Œæ“ä½œé«”é©—æ¥è¿‘ Fargateï¼Œä½†æˆæœ¬å’Œå½ˆæ€§å‰‡æ›´åƒ EC2ã€‚

---

## Terraform Example: Architecture Overview
## Terraform ç¯„ä¾‹ï¼šæ¶æ§‹æ¦‚è¿°

The `main.tf` file wires everything together in `ap-east-2`. At a high level it does the following:
`main.tf` æª”æ¡ˆåœ¨ `ap-east-2` å€åŸŸå°‡æ‰€æœ‰å…ƒä»¶ä¸²æ¥åœ¨ä¸€èµ·ã€‚åœ¨é«˜å±¤æ¬¡ä¸Šï¼Œå®ƒåŸ·è¡Œä»¥ä¸‹æ“ä½œï¼š

- **Provider and Version Requirements**
- **Provider å’Œç‰ˆæœ¬éœ€æ±‚**

  - Uses the `hashicorp/aws` provider, version `>= 6.25.0`, to support the `managed_instances_provider` configuration.
  - ä½¿ç”¨ `hashicorp/aws` providerï¼Œç‰ˆæœ¬ `>= 6.25.0`ï¼Œä»¥æ”¯æ´ `managed_instances_provider` è¨­å®šã€‚

- **Networking and Security Groups**
- **ç¶²è·¯å’Œå®‰å…¨ç¾¤çµ„**

  - Uses `data "aws_subnets"` to fetch private subnets from an existing VPC.
  - ä½¿ç”¨ `data "aws_subnets"` å¾ç¾æœ‰ VPC ä¸­å–å¾—ç§æœ‰å­ç¶²è·¯ã€‚

  - Creates two security groups:
  - å»ºç«‹å…©å€‹å®‰å…¨ç¾¤çµ„ï¼š

    - `ecs_instances`: for EC2 instances, allowing outbound traffic.
    - `ecs_instances`ï¼šç”¨æ–¼ EC2 å¯¦ä¾‹ï¼Œå…è¨±å‡ºç«™æµé‡ã€‚

    - `ecs_tasks`: for ECS tasks, allowing inbound HTTP (port 80/tcp) so requests can reach Nginx.
    - `ecs_tasks`ï¼šç”¨æ–¼ ECS ä»»å‹™ï¼Œå…è¨±å…¥ç«™ HTTPï¼ˆé€£æ¥åŸ  80/tcpï¼‰ï¼Œä»¥ä¾¿è«‹æ±‚å¯ä»¥åˆ°é” Nginxã€‚

- **IAM Roles and Instance Profile**
- **IAM è§’è‰²å’Œå¯¦ä¾‹è¨­å®šæª”**

  - `ecs_infrastructure_role`: used by the ECS infrastructure (Managed Instances), attached with:
  - `ecs_infrastructure_role`ï¼šç”± ECS åŸºç¤è¨­æ–½ï¼ˆManaged Instancesï¼‰ä½¿ç”¨ï¼Œé™„åŠ ï¼š

    - `arn:aws:iam::aws:policy/AmazonECSInfrastructureRolePolicyForManagedInstances`.
    - `arn:aws:iam::aws:policy/AmazonECSInfrastructureRolePolicyForManagedInstances`ã€‚

  - `ecs_instance_role`: used by EC2 instances, attached with:
  - `ecs_instance_role`ï¼šç”± EC2 å¯¦ä¾‹ä½¿ç”¨ï¼Œé™„åŠ ï¼š

    - `AmazonEC2ContainerServiceforEC2Role`
    - `AmazonEC2ContainerServiceforEC2Role`

  - `ecs_task_execution_role`: ECS task execution role, attached with:
  - `ecs_task_execution_role`ï¼šECS ä»»å‹™åŸ·è¡Œè§’è‰²ï¼Œé™„åŠ ï¼š

    - `AmazonECSTaskExecutionRolePolicy` (image pulls, logging, etc.).
    - `AmazonECSTaskExecutionRolePolicy`ï¼ˆæ˜ åƒæª”æ‹‰å–ã€æ—¥èªŒè¨˜éŒ„ç­‰ï¼‰ã€‚

- **ECS Cluster and Capacity Provider**
- **ECS å¢é›†å’Œå®¹é‡æä¾›è€…**

  - Creates an ECS cluster: `managed-instances-cluster`.
  - å»ºç«‹ ECS å¢é›†ï¼š`managed-instances-cluster`ã€‚

  - Creates a capacity provider `managed-instances-cp` using `managed_instances_provider`:
  - ä½¿ç”¨ `managed_instances_provider` å»ºç«‹å®¹é‡æä¾›è€… `managed-instances-cp`ï¼š

    - Sets `infrastructure_role_arn` and `instance_launch_template`.
    - è¨­å®š `infrastructure_role_arn` å’Œ `instance_launch_template`ã€‚

    - Uses `instance_requirements` to define the desired EC2 pool:
    - ä½¿ç”¨ `instance_requirements` å®šç¾©æ‰€éœ€çš„ EC2 æ± ï¼š

      - vCPU between 2â€“4, memory between 3â€“6 GiB.
      - vCPU ä»‹æ–¼ 2-4 ä¹‹é–“ï¼Œè¨˜æ†¶é«”ä»‹æ–¼ 3-6 GiB ä¹‹é–“ã€‚

      - `cpu_manufacturers = ["amazon-web-services"]` to prefer Graviton (e.g. t4g, c7g, m7g).
      - `cpu_manufacturers = ["amazon-web-services"]` ä»¥å„ªå…ˆä½¿ç”¨ Gravitonï¼ˆä¾‹å¦‚ t4gã€c7gã€m7gï¼‰ã€‚

      - Excludes very small instance types (`t4g.nano`, `t4g.micro`, `t4g.small`).
      - æ’é™¤éå¸¸å°çš„å¯¦ä¾‹é¡å‹ï¼ˆ`t4g.nano`ã€`t4g.micro`ã€`t4g.small`ï¼‰ã€‚

    - Configures `network_configuration` to use private subnets and the `ecs_instances` security group.
    - è¨­å®š `network_configuration` ä»¥ä½¿ç”¨ç§æœ‰å­ç¶²è·¯å’Œ `ecs_instances` å®‰å…¨ç¾¤çµ„ã€‚

    - Defines `storage_configuration` and sets `monitoring = "BASIC"`.
    - å®šç¾© `storage_configuration` ä¸¦è¨­å®š `monitoring = "BASIC"`ã€‚

  - Uses `aws_ecs_cluster_capacity_providers` to attach the capacity provider to the cluster and make it the default strategy.
  - ä½¿ç”¨ `aws_ecs_cluster_capacity_providers` å°‡å®¹é‡æä¾›è€…é™„åŠ åˆ°å¢é›†ä¸¦å°‡å…¶è¨­ç‚ºé è¨­ç­–ç•¥ã€‚

- **Task Definition and Nginx Service**
- **ä»»å‹™å®šç¾©å’Œ Nginx æœå‹™**

  - Task definition `nginx-task`:
  - ä»»å‹™å®šç¾© `nginx-task`ï¼š

    - `network_mode = "awsvpc"` and `requires_compatibilities = ["EC2", "MANAGED_INSTANCES"]`.
    - `network_mode = "awsvpc"` ä¸” `requires_compatibilities = ["EC2", "MANAGED_INSTANCES"]`ã€‚

    - `runtime_platform` set to `LINUX` with `ARM64` to match Graviton instances.
    - `runtime_platform` è¨­å®šç‚º `LINUX` æ­é… `ARM64` ä»¥åŒ¹é… Graviton å¯¦ä¾‹ã€‚

    - Container image: `public.ecr.aws/nginx/nginx:1.27-alpine-arm64v8`, exposing port 80 and sending logs to CloudWatch Logs (`/ecs/nginx-managed-instances`) via `awslogs`.
    - å®¹å™¨æ˜ åƒæª”ï¼š`public.ecr.aws/nginx/nginx:1.27-alpine-arm64v8`ï¼Œæš´éœ²é€£æ¥åŸ  80 ä¸¦é€é `awslogs` å°‡æ—¥èªŒå‚³é€åˆ° CloudWatch Logsï¼ˆ`/ecs/nginx-managed-instances`ï¼‰ã€‚

  - ECS service `nginx-service`:
  - ECS æœå‹™ `nginx-service`ï¼š

    - `desired_count = 1` and a `capacity_provider_strategy` pointing to `managed-instances-cp`.
    - `desired_count = 1` ä¸” `capacity_provider_strategy` æŒ‡å‘ `managed-instances-cp`ã€‚

    - Uses the same private subnets and the `ecs_tasks` security group.
    - ä½¿ç”¨ç›¸åŒçš„ç§æœ‰å­ç¶²è·¯å’Œ `ecs_tasks` å®‰å…¨ç¾¤çµ„ã€‚

In other words, with a single `terraform apply` you get:
æ›å¥è©±èªªï¼Œé€éå–®ä¸€ `terraform apply` æ‚¨å¯ä»¥ç²å¾—ï¼š

- An ECS cluster backed by ECS Managed Instances.
- ç”± ECS Managed Instances æ”¯æ’çš„ ECS å¢é›†ã€‚

- A service that triggers ECS to spin up EC2 capacity and then launch an Nginx task.
- è§¸ç™¼ ECS å•Ÿå‹• EC2 å®¹é‡ä¸¦åŸ·è¡Œ Nginx ä»»å‹™çš„æœå‹™ã€‚

- CloudWatch Logs and basic monitoring already wired in.
- å·²é å…ˆè¨­å®šå¥½çš„ CloudWatch Logs å’ŒåŸºæœ¬ç›£æ§ã€‚

## Example Deploy Demo Infra
```bash
# init 
terraform init

# apply
terraform apply
```
![](./images/0-1.png)
```bash
# Destroy
terraform destroy
```
---

## Measuring Cold Start: From Requesting 1 Task to Nginx Logging
## æ¸¬é‡å†·å•Ÿå‹•ï¼šå¾è«‹æ±‚ 1 å€‹ä»»å‹™åˆ° Nginx è¨˜éŒ„æ—¥èªŒ

To understand the cold-start behavior of Managed Instances, we used a small script that continuously lists container instances in the cluster.
ç‚ºäº†äº†è§£ Managed Instances çš„å†·å•Ÿå‹•è¡Œç‚ºï¼Œæˆ‘å€‘ä½¿ç”¨äº†ä¸€å€‹å°è…³æœ¬æŒçºŒåˆ—å‡ºå¢é›†ä¸­çš„å®¹å™¨å¯¦ä¾‹ã€‚

### Monitoring Script
### ç›£æ§è…³æœ¬

```bash
bash -c 'while true; do date && aws ecs list-container-instances --cluster managed-instances-cluster;done'
```

This prints the current time and the result of `aws ecs list-container-instances` every second so we can see:
é€™æœƒæ¯ç§’åˆ—å°ç•¶å‰æ™‚é–“å’Œ `aws ecs list-container-instances` çš„çµæœï¼Œè®“æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼š

- When there are no EC2 instances registered to the cluster.
- å¢é›†ä¸­ä½•æ™‚æ²’æœ‰å·²è¨»å†Šçš„ EC2 å¯¦ä¾‹ã€‚

- When the first managed instance appears and registers with ECS.
- ç¬¬ä¸€å€‹å—ç®¡å¯¦ä¾‹ä½•æ™‚å‡ºç¾ä¸¦è¨»å†Šåˆ° ECSã€‚

### Timeline and Results
### æ™‚é–“ç·šå’Œçµæœ

Here's the timeline from "requesting 1 Nginx task" to "Nginx starting to write logs":
ä»¥ä¸‹æ˜¯å¾ã€Œè«‹æ±‚ 1 å€‹ Nginx ä»»å‹™ã€åˆ°ã€ŒNginx é–‹å§‹å¯«å…¥æ—¥èªŒã€çš„æ™‚é–“ç·šï¼š

```bash
17:04:46 request 1 task 
-> (19s)
17:05:5 container instance running (c6g.large) 
-> (15s)  (pending) -> (running)
17:05:20 task running 
-> (7s)
17:05:27 application (nginx) logging
```

Interpreted step-by-step:
é€æ­¥è§£è®€ï¼š

- **0s**: Request to start one Nginx task on `managed-instances-cluster`.
- **0 ç§’**ï¼šè«‹æ±‚åœ¨ `managed-instances-cluster` ä¸Šå•Ÿå‹•ä¸€å€‹ Nginx ä»»å‹™ã€‚
- ![](./images/0.png)
- ![](./images/1.png)
- **~19s later**: The first managed instance (in this run, `c6g.large`) is launched and registered to the ECS cluster.
- **ç´„ 19 ç§’å¾Œ**ï¼šç¬¬ä¸€å€‹å—ç®¡å¯¦ä¾‹ï¼ˆæ­¤æ¬¡åŸ·è¡Œç‚º `c6g.large`ï¼‰å•Ÿå‹•ä¸¦è¨»å†Šåˆ° ECS å¢é›†ã€‚
- ![](./images/2.png)

- **~15s after that**: The ECS task reaches `RUNNING` state.
- **ä¹‹å¾Œç´„ 15 ç§’**ï¼šECS ä»»å‹™é”åˆ° `RUNNING` ç‹€æ…‹ã€‚
- ![](./images/3.png)


- **~7s later**: Nginx starts writing application logs to CloudWatch Logs.
- **å†éç´„ 7 ç§’**ï¼šNginx é–‹å§‹å°‡æ‡‰ç”¨ç¨‹å¼æ—¥èªŒå¯«å…¥ CloudWatch Logsã€‚
- ![](./images/5.png)
- ![](./images/6.png)

So, from "no container instances at all" to "Nginx actually serving and logging" you're looking at roughly:
å› æ­¤ï¼Œå¾ã€Œå®Œå…¨æ²’æœ‰å®¹å™¨å¯¦ä¾‹ã€åˆ°ã€ŒNginx å¯¦éš›æœå‹™ä¸¦è¨˜éŒ„æ—¥èªŒã€å¤§ç´„éœ€è¦ï¼š

> **19s (bring up EC2 + register) + 15s (pull image & start container) + 7s (app startup & first logs) â‰’ 41 seconds**
> **19 ç§’ï¼ˆå•Ÿå‹• EC2 + è¨»å†Šï¼‰+ 15 ç§’ï¼ˆæ‹‰å–æ˜ åƒæª” & å•Ÿå‹•å®¹å™¨ï¼‰+ 7 ç§’ï¼ˆæ‡‰ç”¨ç¨‹å¼å•Ÿå‹• & é¦–æ¬¡æ—¥èªŒï¼‰â‰’ 41 ç§’**

For many back-office services, internal tools, or low-QPS control-plane style workloads:
å°æ–¼è¨±å¤šå¾Œå°æœå‹™ã€å…§éƒ¨å·¥å…·æˆ–ä½ QPS æ§åˆ¶å¹³é¢é¡å‹çš„å·¥ä½œè² è¼‰ï¼š

- This cold-start time is perfectly reasonable.
- é€™å€‹å†·å•Ÿå‹•æ™‚é–“å®Œå…¨åˆç†ã€‚

- You still gain the cost benefits and flexibility of EC2/Graviton.
- æ‚¨ä»ç„¶å¯ä»¥ç²å¾— EC2/Graviton çš„æˆæœ¬å„ªå‹¢å’Œå½ˆæ€§ã€‚

---

## When to Consider ECS Managed Instances
## ä½•æ™‚è€ƒæ…®ä½¿ç”¨ ECS Managed Instances

Some scenarios where ECS Managed Instances can be a great fit:
ä»¥ä¸‹æ˜¯ ECS Managed Instances éå¸¸é©åˆçš„ä¸€äº›å ´æ™¯ï¼š

- **You want EC2 flexibility and cost-efficiency without maintaining ASGs yourself.**
- **æ‚¨æƒ³è¦ EC2 çš„å½ˆæ€§å’Œæˆæœ¬æ•ˆç›Šï¼Œä½†ä¸æƒ³è‡ªå·±ç¶­è­· ASGã€‚**

- **Your workloads are bursty or intermittent**, and you're okay with tens of seconds of cold start to avoid paying for idle EC2 capacity.
- **æ‚¨çš„å·¥ä½œè² è¼‰å…·æœ‰çªç™¼æ€§æˆ–é–“æ­‡æ€§**ï¼Œæ‚¨å¯ä»¥æ¥å—æ•¸åç§’çš„å†·å•Ÿå‹•æ™‚é–“ï¼Œä»¥é¿å…ç‚ºé–’ç½®çš„ EC2 å®¹é‡ä»˜è²»ã€‚

- **You need specific instance attributes** (e.g. must run on Graviton, must have local NVMe, or must leverage Spot), but still want to orchestrate everything using ECS capacity provider strategies.
- **æ‚¨éœ€è¦ç‰¹å®šçš„å¯¦ä¾‹å±¬æ€§**ï¼ˆä¾‹å¦‚å¿…é ˆåœ¨ Graviton ä¸Šé‹è¡Œã€å¿…é ˆæœ‰æœ¬åœ° NVMeã€æˆ–å¿…é ˆåˆ©ç”¨ Spotï¼‰ï¼Œä½†ä»å¸Œæœ›ä½¿ç”¨ ECS å®¹é‡æä¾›è€…ç­–ç•¥ä¾†ç·¨æ’ä¸€åˆ‡ã€‚


If you're already familiar with ECS on EC2 or Fargate and want a **more hands-off way of managing EC2 capacity**, this `ecs-mg` example is a good starting point.
å¦‚æœæ‚¨å·²ç¶“ç†Ÿæ‚‰ ECS on EC2 æˆ– Fargateï¼Œä¸¦ä¸”æƒ³è¦ä¸€ç¨®**æ›´çœäº‹çš„ EC2 å®¹é‡ç®¡ç†æ–¹å¼**ï¼Œé€™å€‹ `ecs-mg` ç¯„ä¾‹æ˜¯ä¸€å€‹å¾ˆå¥½çš„èµ·é»ã€‚

Just run `terraform apply`, watch the cluster come to life, and observe how Managed Instances handle capacity and cold starts for your Nginx service.
åªéœ€åŸ·è¡Œ `terraform apply`ï¼Œè§€å¯Ÿå¢é›†å•Ÿå‹•ï¼Œä¸¦è§€å¯Ÿ Managed Instances å¦‚ä½•ç‚ºæ‚¨çš„ Nginx æœå‹™è™•ç†å®¹é‡å’Œå†·å•Ÿå‹•ã€‚

--- 

## Findings / ç™¼ç¾ä¸€äº›äº‹æƒ…

### 1. ECS Service Connect with ECS Exec on Managed Instance has connection issues
### 1. ç•¶ ECS Service Connect èˆ‡ ECS Exec åŒæ™‚å•Ÿç”¨æ™‚ï¼ŒManaged Instance ä¸Šçš„ Task ç„¡æ³•æ­£å¸¸é€£ç·š

> If you deploy this Terraform example repo, the `nginx-service` will enable both ECS Service Connect and ECS Exec running on Managed Instance.
> 
> å¦‚æœä½ éƒ¨ç½²äº†é€™å€‹ Terraform ç¯„ä¾‹ï¼Œ`nginx-service` æœƒåŒæ™‚é–‹å•Ÿ ECS Service Connect ä»¥åŠ ECS Execï¼Œä¸¦é‹è¡Œæ–¼ Managed Instance ä¸Šã€‚

**Example / ç¯„ä¾‹ï¼š**

```bash
aws ecs list-services --cluster managed-instances-cluster --region ap-east-2 --query 'serviceArns[]' --output table
# ------------------------------------------------------------------------------------------------
# |                                         ListServices                                         |
# +----------------------------------------------------------------------------------------------+
# |  arn:aws:ecs:ap-east-2:012345678912:service/managed-instances-cluster/nginx-service-exec-ok  |
# |  arn:aws:ecs:ap-east-2:012345678912:service/managed-instances-cluster/nginx-service-fargate  |
# |  arn:aws:ecs:ap-east-2:012345678912:service/managed-instances-cluster/nginx-service          |
# +----------------------------------------------------------------------------------------------+

bash scripts/check-exec-connect.bash \
  --cluster managed-instances-cluster \
  --region ap-east-2 \
  --service nginx-service
```

![](./images/nginx-service.png)

---

> The `nginx-service-exec-ok` service only enables ECS Exec running on Managed Instance.
> 
> `nginx-service-exec-ok` æœå‹™åƒ…é–‹å•Ÿ ECS Execï¼Œé‹è¡Œæ–¼ Managed Instance ä¸Šã€‚

**Example / ç¯„ä¾‹ï¼š**

```bash
bash scripts/check-exec-connect.bash \
  --cluster managed-instances-cluster \
  --region ap-east-2 \
  --service nginx-service-exec-ok
```

![](./images/nginx-service-exec-ok.png)

---

> The `nginx-service-fargate` service enables both ECS Service Connect and ECS Exec running on Fargate.
> 
> `nginx-service-fargate` æœå‹™åŒæ™‚é–‹å•Ÿ ECS Service Connect ä»¥åŠ ECS Execï¼Œé‹è¡Œæ–¼ Fargate ä¸Šã€‚

**Example / ç¯„ä¾‹ï¼š**

```bash
bash scripts/check-exec-connect.bash \
  --cluster managed-instances-cluster \
  --region ap-east-2 \
  --service nginx-service-fargate
```

![](./images/nginx-service-fargate.png)

---

### Summary Table / ç¸½çµè¡¨æ ¼

| Service Name | Launch Type | ECS Service Connect | ECS Exec | Result |
|:-------------|:------------|:-------------------:|:--------:|:------:|
| `nginx-service` | Managed Instance (EC2) | âœ… Enabled | âœ… Enabled | âŒ **Connection Failed** |
| `nginx-service-exec-ok` | Managed Instance (EC2) | âŒ Disabled | âœ… Enabled | âœ… **Works** |
| `nginx-service-fargate` | Fargate | âœ… Enabled | âœ… Enabled | âœ… **Works** |

| æœå‹™åç¨± | å•Ÿå‹•é¡å‹ | ECS Service Connect | ECS Exec | çµæœ |
|:---------|:---------|:-------------------:|:--------:|:----:|
| `nginx-service` | Managed Instance (EC2) | âœ… å•Ÿç”¨ | âœ… å•Ÿç”¨ | âŒ **é€£ç·šå¤±æ•—** |
| `nginx-service-exec-ok` | Managed Instance (EC2) | âŒ åœç”¨ | âœ… å•Ÿç”¨ | âœ… **æ­£å¸¸** |
| `nginx-service-fargate` | Fargate | âœ… å•Ÿç”¨ | âœ… å•Ÿç”¨ | âœ… **æ­£å¸¸** |

### Architecture Diagram / æ¶æ§‹æ„è±¡åœ–
![](./images/summary.png)
### Conclusion / çµè«–

> **Issue**: When both ECS Service Connect and ECS Exec are enabled on a Managed Instance (EC2), the ECS Exec connection fails.
> 
> **å•é¡Œ**ï¼šç•¶ Managed Instance (EC2) åŒæ™‚å•Ÿç”¨ ECS Service Connect èˆ‡ ECS Exec æ™‚ï¼ŒECS Exec é€£ç·šæœƒå¤±æ•—ã€‚

> **Workaround**: Either disable ECS Service Connect on Managed Instance, or use Fargate instead.
> 
> **è§£æ±ºæ–¹æ³•**ï¼šåœ¨ Managed Instance ä¸Šåœç”¨ ECS Service Connectï¼Œæˆ–æ”¹ç”¨ Fargateã€‚

## ğŸš¨ğŸš¨ğŸš¨ This issue was reported to AWS Support on 2025/12/25 and is currently awaiting a response.
## ğŸš¨ğŸš¨ğŸš¨ è©²å•é¡Œå·²ç¶“åœ¨ 2025/12/25 å›å ±çµ¦ AWS Supportï¼Œç›®å‰ç­‰å¾…å›æ‡‰ä¸­
---
sources:
- https://aws.amazon.com/tw/about-aws/whats-new/2025/09/amazon-ecs-managed-instances/
- https://aws.amazon.com/tw/about-aws/whats-new/2025/12/amazon-ecs-managed-instances-ec2-spot-instances/

## Date: 2026/01/17 
## Author: Neil Kuan